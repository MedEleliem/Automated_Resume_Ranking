{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 2\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    \n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_SpeChar(text):\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    text= re.sub('\\S*@\\S*\\s?', '', text)\n",
    "    text = re.sub('[!\"#$%&()*+,./:;<=>?@[\\]^_`{|}~‘’•]', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_StopWords(text):\n",
    "    sentence = nlp(text)\n",
    "    filtered_sentence = ''\n",
    "    token_list = []\n",
    "    for token in sentence : \n",
    "        token_list.append(token.text)\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False :\n",
    "            filtered_sentence += ' '+word\n",
    "    return filtered_sentence\n",
    "\n",
    "\n",
    "def get_lem(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "def remove_Ent(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'DATE' : \n",
    "            text = re.sub(ent.text,' ',text)\n",
    "        elif ent.label_ == 'PERSON' : \n",
    "            text = re.sub(ent.text,' ',text)\n",
    "        elif ent.label_ == 'GPE' : \n",
    "            text = re.sub(ent.text,' ',text)\n",
    "    return text\n",
    "\n",
    "def get_low(text):\n",
    "    return text.lower()\n",
    "            \n",
    "\n",
    "def main_(path):\n",
    "    text = convert_pdf_to_txt(path)\n",
    "    text = remove_SpeChar(text)\n",
    "    text = remove_StopWords(text)\n",
    "    text = remove_Ent(text)\n",
    "    text = get_lem(text)\n",
    "    text = get_low(text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = main_(r\"C:\\Users\\Med El-Eliem\\stage\\Resume\\CV_Mohamed_EL-ELIEM--ENG.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insea ORG\n",
      "ibm ORG\n",
      "ibm ORG\n",
      "svm https PRODUCT\n",
      "linear ORG\n",
      "linear ORG\n",
      "arabic LANGUAGE\n",
      "english LANGUAGE\n",
      "french NORP\n",
      "hadoop mongodb PERSON\n",
      "spss GPE\n",
      "algorithms cross ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(b)\n",
    "entity=doc.ents \n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  academic formations engineering degree statistics demography department national institut statistics applied economy insea rabat preparatory classes engineering schools mathematics physic cpge taza mathematics physic industrial sciences cpge taza baccalaureate degree mathematical sciences el wahda high school taounate certiﬁcations professional trainning progress google professional certificate data engineering gcp certificate course    ibm professional certificate ibm data science course https bit ly coursera guided project support vector machine scikit learn https bit ly    university michigan specialisation statistic python course https bit ly individuals project progress machine learning model face recognition ai project extract main feature image principal component analysis pca recognize image support vector machine classifier svm https bit ly    classify neighboorhood    unsupervise machine learning datascience project k mean clustering k select elbow method https bit ly    linear regression model car consumption prediction datascience anova test consumption mean group age car predict multiple linear regression https bit ly    inscription website insea student stack web dev    sql php interests gaming design culture languages arabic english french    eliem statistics datascience engineering student contact me eleliem gmail com    route ain chqef fes morocco    eliem    medeleliem technical skills python sk learnstat models pandas folium foursquare opencv matplotlibseaborn numpy r program hadoop mongodb sql    php spss net e views machine learning algorithms cross validation data management data scrapping data wrangling data standardization data analysis data visualization'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
